\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{ieeetr}
\providecommand \oddpage@label [2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{Sutton-introRL}
\citation{Goodfellow-et-al-2016}
\citation{macwhinne_lang_evol}
\citation{turing_mind}
\citation{kurzweil_sing}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{8}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Overview}{8}{subsection.1.1}}
\citation{Weizenbaum:1966:ECP:365153.365168}
\citation{ncf2017}
\citation{frey2017future}
\citation{Tao_of_CHI}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Motivation}{10}{subsection.1.2}}
\newlabel{plag1}{{1.2}{10}{Motivation}{subsection.1.2}{}}
\newlabel{plag10}{{1.2}{10}{Motivation}{subsection.1.2}{}}
\citation{zue_jupiter}
\citation{Larsson:2000:ISD:973935.973943}
\citation{mdp-bellmann}
\citation{mdp-pieraccini}
\citation{Young99probabilisticmethods}
\citation{Singh_mdp}
\citation{Pietquin_mdp}
\citation{Dhingra2016EndtoEndRL}
\citation{Cuayhuitl2016SimpleDSAS}
\citation{Li17e2eDS}
\citation{HakkaniTr2016NLU}
\citation{Wen_NLG}
\citation{hochreiter1997long}
\citation{Schatzmann_agenda_sim}
\citation{Li_user_sim}
\citation{Mnih_DQN}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}State of the Art}{11}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Dialog Policy trained with Reinforcement Learning}{11}{subsubsection.1.3.1}}
\citation{tensorflow}
\citation{Sutskever_seq_2seq}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Dialog Policy trained with End-to-End Supervised Learning}{12}{subsubsection.1.3.2}}
\citation{karpathy_rnn}
\citation{hochreiter1998vanishing}
\citation{hochreiter1997long}
\citation{Sukhbaatar_end2end_mem_net}
\citation{babl}
\citation{bordes_weston_e2e}
\citation{Su_continous_dm}
\citation{Schulman_trpo}
\citation{Sutton_pg}
\citation{Lin1992}
\citation{Williams_HCN_e2e}
\citation{Sutton_pg}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Dialog Policy trained with a Combined Approach}{13}{subsubsection.1.3.3}}
\citation{mdp-pieraccini}
\citation{ds_survey}
\citation{Pieraccini2006WhereDW}
\citation{ml_dst_review}
\@writefile{toc}{\contentsline {section}{\numberline {2}Dialog Systems}{15}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overview}{15}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}System Architecture}{15}{subsection.2.2}}
\newlabel{subsec:sys-arch}{{2.2}{15}{System Architecture}{subsection.2.2}{}}
\citation{mdp-bellmann}
\citation{mdp-pieraccini}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Text Based Dialog System Architecture }}{16}{figure.1}}
\newlabel{sys-arch1}{{1}{16}{Text Based Dialog System Architecture}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Dialog Management}{16}{subsection.2.3}}
\citation{Sutton-introRL}
\citation{Larsson:2000:ISD:973935.973943}
\citation{Young_dst_dbn}
\citation{roy2000spoken}
\citation{Henderson:2008:MMP:1557690.1557710}
\citation{Young:2010:HIS:1621140.1621240}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Dialog State Tracking (DST)}{17}{subsubsection.2.3.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.1}Information State DST}{17}{paragraph.2.3.1.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.2}Generative DST}{17}{paragraph.2.3.1.2}}
\citation{generative_dst_limitation}
\citation{Lee2013StructuredDM}
\citation{Henderson2014WordBasedDS}
\citation{Henderson_dst_2014}
\citation{DBLP:journals/corr/MrksicSWTY16}
\citation{Sutton-introRL}
\citation{Larsson:2000:ISD:973935.973943}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.3}Discriminative DST}{18}{paragraph.2.3.1.3}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.4}Our Approach}{18}{paragraph.2.3.1.4}}
\citation{Sutton-introRL}
\citation{DBLP:journals/corr/abs-1711-01731}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Dialog Policy}{19}{subsubsection.2.3.2}}
\citation{henderson_interdomain}
\citation{mdp-pieraccini}
\citation{lopez-cozar-simulation}
\citation{Schatzmann_stat_user_sim}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.2.1}Our Approach}{20}{paragraph.2.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}User Simulation}{20}{subsection.2.4}}
\citation{Chung_user_sim}
\citation{Lopez-Cozar_user-sim}
\citation{Cuayhuitl2006LearningMD}
\citation{levin_mdp}
\citation{4430164}
\citation{Georgila2006UserSF}
\citation{Cuayhuitl2005HumancomputerDS}
\citation{Scheffler_sim}
\citation{Schatzmann2007StatisticalUS}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Rule Based Simulation}{21}{subsubsection.2.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Probabilistic Model Based Simulation}{21}{subsubsection.2.4.2}}
\citation{Scheffler_sim}
\citation{georgila1998integrated}
\citation{chai2001natural}
\citation{su2013dialoguegame}
\citation{ELVIS}
\citation{zue_jupiter}
\citation{Shriver_unified}
\citation{TRAIN}
\citation{ferguson1998trips}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Our Approach}{22}{subsubsection.2.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Applications}{22}{subsection.2.5}}
\citation{Levin97astochastic}
\citation{Levin97astochastic}
\citation{mdp-pieraccini}
\@writefile{toc}{\contentsline {section}{\numberline {3}Technical Background}{23}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overview}{23}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Reinforcement Learning (RL)}{23}{subsection.3.2}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Agent-Environment Interface \cite  {Sutton-introRL} }}{25}{figure.2}}
\newlabel{agent-env-rl}{{2}{25}{Agent-Environment Interface \cite {Sutton-introRL}}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Markov Decision Processes (MDP)}{25}{subsection.3.3}}
\newlabel{subsec:mdp}{{3.3}{25}{Markov Decision Processes (MDP)}{subsection.3.3}{}}
\citation{Sutton-introRL}
\newlabel{eq:1}{{3.1}{26}{Markov Decision Processes (MDP)}{equation.3.1}{}}
\newlabel{eq:2}{{3.2}{26}{Markov Decision Processes (MDP)}{equation.3.2}{}}
\newlabel{eq:3}{{3.3}{26}{Markov Decision Processes (MDP)}{equation.3.3}{}}
\newlabel{eq:4}{{3.4}{26}{Markov Decision Processes (MDP)}{equation.3.4}{}}
\newlabel{eq:5}{{3.5}{26}{Markov Decision Processes (MDP)}{equation.3.5}{}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\newlabel{eq:6}{{3.6}{27}{Markov Decision Processes (MDP)}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Optimality}{27}{subsubsection.3.3.1}}
\newlabel{optimality}{{3.3.1}{27}{Optimality}{subsubsection.3.3.1}{}}
\newlabel{eq:7}{{3.8}{27}{Optimality}{equation.3.8}{}}
\newlabel{eq:8}{{3.9}{27}{Optimality}{equation.3.9}{}}
\newlabel{eq:9}{{3.10}{27}{Optimality}{equation.3.10}{}}
\citation{Young99probabilisticmethods}
\citation{mdp-pieraccini}
\citation{mdp-bellmann}
\citation{Sutton-introRL}
\newlabel{eq:10}{{3.11}{28}{Optimality}{equation.3.11}{}}
\newlabel{eq:11}{{3.12}{28}{Optimality}{equation.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Composing Dialog Management as an MDP}{28}{subsection.3.4}}
\newlabel{dialog-mdp}{{3.4}{28}{Composing Dialog Management as an MDP}{subsection.3.4}{}}
\citation{Larsson:2000:ISD:973935.973943}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Dialog represented as a Markov Decision Process }}{30}{figure.3}}
\newlabel{chat-world3}{{3}{30}{Dialog represented as a Markov Decision Process}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Agent-Environment Interaction }}{31}{figure.4}}
\newlabel{chat-world}{{4}{31}{Agent-Environment Interaction}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Agent-Environment Interaction in the form of a chatbot application }}{33}{figure.5}}
\newlabel{chat-world2}{{5}{33}{Agent-Environment Interaction in the form of a chatbot application}{figure.5}{}}
\citation{rl_overview}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Dialog Policy Optimization}{34}{subsection.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Dialog Policy Optimization Methods }}{34}{figure.6}}
\newlabel{mdp-methods}{{6}{34}{Dialog Policy Optimization Methods}{figure.6}{}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Value Iterative Methods}{35}{subsubsection.3.5.1}}
\newlabel{eq:12}{{3.13}{35}{Value Iterative Methods}{equation.3.13}{}}
\newlabel{eq:13}{{3.14}{35}{Value Iterative Methods}{equation.3.14}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.1}Dynamic Programming}{35}{paragraph.3.5.1.1}}
\newlabel{dp}{{3.5.1.1}{35}{Dynamic Programming}{paragraph.3.5.1.1}{}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\citation{sutton1988TFDearning}
\newlabel{eq:dp-update}{{3.15}{36}{Dynamic Programming}{equation.3.15}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.2}Monte Carlo Learning }{36}{paragraph.3.5.1.2}}
\newlabel{mc-learning}{{3.5.1.2}{36}{Monte Carlo Learning}{paragraph.3.5.1.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.3}Temporal Difference(TD) Learning }{36}{paragraph.3.5.1.3}}
\newlabel{td-learning}{{3.5.1.3}{36}{Temporal Difference(TD) Learning}{paragraph.3.5.1.3}{}}
\citation{sutton1988TFDearning}
\citation{watkins1989Qlearning}
\newlabel{eq:td-error}{{3.16}{37}{Temporal Difference(TD) Learning}{equation.3.16}{}}
\newlabel{eq:td-update}{{3.17}{37}{Temporal Difference(TD) Learning}{equation.3.17}{}}
\newlabel{eq:sarsa-update}{{3.18}{37}{Temporal Difference(TD) Learning}{equation.3.18}{}}
\newlabel{eq:q-update}{{3.19}{37}{Temporal Difference(TD) Learning}{equation.3.19}{}}
\citation{adam2012experience}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces SARSA}}{38}{algocf.1}}
\newlabel{alg:sarsa}{{1}{38}{Temporal Difference(TD) Learning}{algocf.1}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.4}Sample Efficiency}{38}{paragraph.3.5.1.4}}
\citation{verleysen2005curse}
\citation{hornik1989multilayer}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Q-Learning}}{39}{algocf.2}}
\newlabel{alg:q-learning}{{2}{39}{Temporal Difference(TD) Learning}{algocf.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.5}Function Approximation}{39}{paragraph.3.5.1.5}}
\newlabel{fn_aprrox}{{3.5.1.5}{39}{Function Approximation}{paragraph.3.5.1.5}{}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Policy Iterative Methods}{40}{subsubsection.3.5.2}}
\newlabel{policy_methods}{{3.5.2}{40}{Policy Iterative Methods}{subsubsection.3.5.2}{}}
\newlabel{eq:17}{{3.25}{41}{Policy Iterative Methods}{equation.3.25}{}}
\citation{Sutton-introRL}
\citation{Sutton_pg}
\citation{Sutton-introRL}
\citation{Sutton_pg}
\newlabel{eq:obj_value}{{3.28}{42}{Policy Iterative Methods}{equation.3.28}{}}
\newlabel{eq:vpg_update}{{3.30}{42}{Policy Iterative Methods}{equation.3.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Actor-Critic Methods}{42}{subsubsection.3.5.3}}
\newlabel{section:ac-methods}{{3.5.3}{42}{Actor-Critic Methods}{subsubsection.3.5.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Actor-Critic Environment Interaction }}{43}{figure.7}}
\newlabel{a-c}{{7}{43}{Actor-Critic Environment Interaction}{figure.7}{}}
\newlabel{eq:pg-theorem}{{3.31}{43}{Actor-Critic Methods}{equation.3.31}{}}
\newlabel{eq:ac-conv}{{3.32}{43}{Actor-Critic Methods}{equation.3.32}{}}
\citation{peters2005natural}
\citation{Sutton_pg}
\citation{peters2005natural}
\citation{Sutton_pg}
\citation{bordes2016learning}
\citation{liu2016not}
\newlabel{eq:pg-compatible}{{3.33}{44}{Actor-Critic Methods}{equation.3.33}{}}
\newlabel{eq:ac-error}{{3.34}{44}{Actor-Critic Methods}{equation.3.34}{}}
\newlabel{eq:pg-f}{{3.35}{44}{Actor-Critic Methods}{equation.3.35}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Evaluation and Reward Estimation}{44}{subsection.3.6}}
\citation{Williams:2007:POM:1221595.1221967}
\citation{DBLP:journals/corr/abs-1711-01731}
\citation{lemon2006evaluating}
\citation{walker1997paradise}
\citation{larsen2003issues}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Heuristic Rewards}{45}{subsubsection.3.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}The Paradise Framework}{45}{subsubsection.3.6.2}}
\citation{mataric1994reward}
\citation{ng1999policy}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Reward Shaping}{46}{subsubsection.3.6.3}}
\newlabel{eg:reward-shaping-condition}{{3.38}{46}{Reward Shaping}{equation.3.38}{}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Auxiliary RL terminology}{47}{subsection.3.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1}Model-based and Model-free}{47}{subsubsection.3.7.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.2}Episodic and Continuous Tasks}{47}{subsubsection.3.7.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.3}On-line and Off-line}{48}{subsubsection.3.7.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.4}On Policy and Off Policy}{48}{subsubsection.3.7.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.5}Exploration and Exploitation}{48}{subsubsection.3.7.5}}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {section}{\numberline {4}Deep Learning}{49}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Overview}{49}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Deep Feedforward Networks}{49}{subsection.4.2}}
\citation{LeCun:1998:CNI:303568.303704}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Loss Functions}{50}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Fully Connected Neural Network }}{51}{figure.8}}
\newlabel{nn-fully-connected}{{8}{51}{Fully Connected Neural Network}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Maximum Likelihood Estimation}{51}{subsubsection.4.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Approximating Conditional Distributions with Maximum Likelihood}{52}{subsubsection.4.3.2}}
\newlabel{eq:mse_loss}{{4.7}{52}{Approximating Conditional Distributions with Maximum Likelihood}{equation.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Output Units}{53}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Linear Units}{53}{subsubsection.4.4.1}}
\newlabel{linear_unit}{{4.4.1}{53}{Linear Units}{subsubsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Sigmoid Units}{53}{subsubsection.4.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Softmax Units}{53}{subsubsection.4.4.3}}
\newlabel{softmax}{{4.4.3}{53}{Softmax Units}{subsubsection.4.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Hidden Units}{54}{subsection.4.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Rectified Linear Units(ReLU)}{54}{subsubsection.4.5.1}}
\citation{jarrett2009best}
\citation{maas2013rectifier}
\citation{he2015delving}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Rectified Linear Unit }}{55}{figure.9}}
\newlabel{relu}{{9}{55}{Rectified Linear Unit}{figure.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}The Hyperbolic Tangent and Logistic Sigmoid}{56}{subsubsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Logistic Sigmoid Unit }}{56}{figure.10}}
\newlabel{sigmoid}{{10}{56}{Logistic Sigmoid Unit}{figure.10}{}}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Hyperbolic Tangent Unit }}{57}{figure.11}}
\newlabel{tanh}{{11}{57}{Hyperbolic Tangent Unit}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Architecture}{57}{subsection.4.6}}
\citation{Goodfellow-et-al-2016}
\citation{cauchy1847methode}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces General Architecture of a Neural Network }}{58}{figure.12}}
\newlabel{nn_arch}{{12}{58}{General Architecture of a Neural Network}{figure.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Gradient Based Learning}{58}{subsection.4.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The Process of Gradient Descent\cite  {Goodfellow-et-al-2016} }}{59}{figure.13}}
\newlabel{grad_descent}{{13}{59}{The Process of Gradient Descent\cite {Goodfellow-et-al-2016}}{figure.13}{}}
\citation{rumelhart1986learning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.1}Back-Propagation}{60}{subsubsection.4.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Back Propagating Errors Through a Neural Network }}{60}{figure.14}}
\newlabel{back_prop}{{14}{60}{Back Propagating Errors Through a Neural Network}{figure.14}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Forward Propagation through a deep neural network and the loss computation}}{61}{algocf.3}}
\newlabel{alg:forward-prop}{{3}{61}{Back-Propagation}{algocf.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.2}Stochastic Gradient Descent(SGD)}{61}{subsubsection.4.7.2}}
\newlabel{sgd}{{4.7.2}{61}{Stochastic Gradient Descent(SGD)}{subsubsection.4.7.2}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Back Propagation}}{62}{algocf.4}}
\newlabel{alg:back-prop}{{4}{62}{Back-Propagation}{algocf.4}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Stochastic Gradient Descent Algorithm}}{62}{algocf.5}}
\newlabel{alg:sgd}{{5}{62}{Stochastic Gradient Descent(SGD)}{algocf.5}{}}
\citation{Williams92REINFORCE}
\@writefile{toc}{\contentsline {section}{\numberline {5}Neural Dialog Management}{63}{section.5}}
\newlabel{dm-with-drl}{{5}{63}{Neural Dialog Management}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Overview}{63}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}REINFORCE}{63}{subsection.5.2}}
\newlabel{eq:pg-expectation}{{5.1}{63}{REINFORCE}{equation.5.1}{}}
\newlabel{eq:reinforce-update}{{5.4}{64}{REINFORCE}{equation.5.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}REINFORCE Algorithm}{64}{subsubsection.5.2.1}}
\newlabel{reinforce}{{5.2.1}{64}{REINFORCE Algorithm}{subsubsection.5.2.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Policy Network}{64}{subsubsection.5.2.2}}
\citation{kingma2014adam}
\citation{Sutton_pg}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces REINFORCE}}{65}{algocf.6}}
\newlabel{alg:reinforce}{{6}{65}{REINFORCE Algorithm}{algocf.6}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Advantage Actor Critic}{65}{subsection.5.3}}
\newlabel{a2c-section}{{5.3}{65}{Advantage Actor Critic}{subsection.5.3}{}}
\citation{Sutton_pg}
\citation{Sutton-introRL}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Policy Neural Network }}{66}{figure.15}}
\newlabel{nn-policy}{{15}{66}{Policy Neural Network}{figure.15}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Advantage Function}{66}{subsubsection.5.3.1}}
\citation{Sutton-introRL}
\citation{Williams92REINFORCE}
\newlabel{eq:baseline}{{5.5}{67}{Advantage Function}{equation.5.5}{}}
\newlabel{eq:adv}{{5.6}{67}{Advantage Function}{equation.5.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}A2C Algorithm}{67}{subsubsection.5.3.2}}
\citation{Sutton-introRL}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Actor-Critic Environment Interaction }}{68}{figure.16}}
\newlabel{a2c}{{16}{68}{Actor-Critic Environment Interaction}{figure.16}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {7}{\ignorespaces Advantage Actor Critic Algorithm}}{69}{algocf.7}}
\newlabel{alg:a2c}{{7}{69}{A2C Algorithm}{algocf.7}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Actor Network}{69}{subsubsection.5.3.3}}
\citation{kingma2014adam}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Actor Network }}{70}{figure.17}}
\newlabel{nn-actor}{{17}{70}{Actor Network}{figure.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Critic Network}{70}{subsubsection.5.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Critic Network }}{71}{figure.18}}
\newlabel{nn-critic}{{18}{71}{Critic Network}{figure.18}{}}
\citation{python}
\citation{tensorflow}
\citation{keras}
\citation{Singh_mdp}
\citation{walker2000evaluation}
\citation{roy2000spoken}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments and Results}{72}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Overview}{72}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Learning Simple Dialog Strategies}{72}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Experimental Setup}{72}{subsubsection.6.2.1}}
\newlabel{expt-setup}{{6.2.1}{72}{Experimental Setup}{subsubsection.6.2.1}{}}
\citation{Larsson:2000:ISD:973935.973943}
\newlabel{eq:trans-prob1}{{6.1}{73}{Experimental Setup}{equation.6.1}{}}
\newlabel{eq:trans-prob2}{{6.2}{73}{Experimental Setup}{equation.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces State Transition Model }}{74}{figure.19}}
\newlabel{state-trans}{{19}{74}{State Transition Model}{figure.19}{}}
\newlabel{eq:trans-prob3}{{6.5}{74}{Experimental Setup}{equation.6.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces User Simulation Model}}{75}{table.1}}
\newlabel{table:user-sim}{{1}{75}{User Simulation Model}{table.1}{}}
\newlabel{reward_func}{{6.6}{76}{Experimental Setup}{equation.6.6}{}}
\citation{Sutton-introRL}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces System Actions}}{77}{table.2}}
\newlabel{table:actions}{{2}{77}{System Actions}{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Learning with A2C}{77}{subsubsection.6.2.2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.1}Results}{77}{paragraph.6.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces A2C Learning Curve }}{79}{figure.20}}
\newlabel{a2c-plot}{{20}{79}{A2C Learning Curve}{figure.20}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.2}Effect of the Discount Factor}{80}{paragraph.6.2.2.2}}
\newlabel{a2c_df_effect}{{6.2.2.2}{80}{Effect of the Discount Factor}{paragraph.6.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Effect of the Discount Factor on A2C Learning }}{81}{figure.21}}
\newlabel{a2c_dis_fact}{{21}{81}{Effect of the Discount Factor on A2C Learning}{figure.21}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.3}Effect of Reward Magnitude}{82}{paragraph.6.2.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Effect of the Absolute Reward Magnitude on A2C Learning }}{83}{figure.22}}
\newlabel{a2c_reward_mag}{{22}{83}{Effect of the Absolute Reward Magnitude on A2C Learning}{figure.22}{}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}Learning with REINFORCE}{84}{subsubsection.6.2.3}}
\newlabel{reward_func_10}{{6.7}{84}{Learning with REINFORCE}{equation.6.7}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.3.1}Results}{84}{paragraph.6.2.3.1}}
\newlabel{reinf_pre_results}{{6.2.3.1}{84}{Results}{paragraph.6.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces REINFORCE Learning Curve }}{85}{figure.23}}
\newlabel{reinforce-plot}{{23}{85}{REINFORCE Learning Curve}{figure.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Summary}{86}{subsection.6.3}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{87}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Conclusion}{87}{subsection.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Future Work}{87}{subsection.7.2}}
\bibstyle{apa}
\bibdata{references}
\bibcite{macwhinne_lang_evol}{{1}{}{{}}{{}}}
\bibcite{turing_mind}{{2}{}{{}}{{}}}
\bibcite{kurzweil_sing}{{3}{}{{}}{{}}}
\bibcite{Weizenbaum:1966:ECP:365153.365168}{{4}{}{{}}{{}}}
\bibcite{ncf2017}{{5}{}{{}}{{}}}
\bibcite{frey2017future}{{6}{}{{}}{{}}}
\bibcite{Tao_of_CHI}{{7}{}{{}}{{}}}
\bibcite{zue_jupiter}{{8}{}{{}}{{}}}
\bibcite{Larsson:2000:ISD:973935.973943}{{9}{}{{}}{{}}}
\bibcite{mdp-bellmann}{{10}{}{{}}{{}}}
\bibcite{mdp-pieraccini}{{11}{}{{}}{{}}}
\bibcite{Young99probabilisticmethods}{{12}{}{{}}{{}}}
\bibcite{Singh_mdp}{{13}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {8}References}{89}{section.8}}
\bibcite{Pietquin_mdp}{{14}{}{{}}{{}}}
\bibcite{Dhingra2016EndtoEndRL}{{15}{}{{}}{{}}}
\bibcite{Cuayhuitl2016SimpleDSAS}{{16}{}{{}}{{}}}
\bibcite{Li17e2eDS}{{17}{}{{}}{{}}}
\bibcite{HakkaniTr2016NLU}{{18}{}{{}}{{}}}
\bibcite{Wen_NLG}{{19}{}{{}}{{}}}
\bibcite{hochreiter1997long}{{20}{}{{}}{{}}}
\bibcite{Schatzmann_agenda_sim}{{21}{}{{}}{{}}}
\bibcite{Li_user_sim}{{22}{}{{}}{{}}}
\bibcite{Mnih_DQN}{{23}{}{{}}{{}}}
\bibcite{tensorflow}{{24}{}{{}}{{}}}
\bibcite{Sutskever_seq_2seq}{{25}{}{{}}{{}}}
\bibcite{karpathy_rnn}{{26}{}{{}}{{}}}
\bibcite{hochreiter1998vanishing}{{27}{}{{}}{{}}}
\bibcite{Sukhbaatar_end2end_mem_net}{{28}{}{{}}{{}}}
\bibcite{babl}{{29}{}{{}}{{}}}
\bibcite{bordes_weston_e2e}{{30}{}{{}}{{}}}
\bibcite{Su_continous_dm}{{31}{}{{}}{{}}}
\bibcite{Schulman_trpo}{{32}{}{{}}{{}}}
\bibcite{Sutton_pg}{{33}{}{{}}{{}}}
\bibcite{Lin1992}{{34}{}{{}}{{}}}
\bibcite{Williams_HCN_e2e}{{35}{}{{}}{{}}}
\bibcite{ds_survey}{{36}{}{{}}{{}}}
\bibcite{Pieraccini2006WhereDW}{{37}{}{{}}{{}}}
\bibcite{ml_dst_review}{{38}{}{{}}{{}}}
\bibcite{Sutton-introRL}{{39}{}{{}}{{}}}
\bibcite{Young_dst_dbn}{{40}{}{{}}{{}}}
\bibcite{roy2000spoken}{{41}{}{{}}{{}}}
\bibcite{Henderson:2008:MMP:1557690.1557710}{{42}{}{{}}{{}}}
\bibcite{Young:2010:HIS:1621140.1621240}{{43}{}{{}}{{}}}
\bibcite{generative_dst_limitation}{{44}{}{{}}{{}}}
\bibcite{Lee2013StructuredDM}{{45}{}{{}}{{}}}
\bibcite{Henderson2014WordBasedDS}{{46}{}{{}}{{}}}
\bibcite{Henderson_dst_2014}{{47}{}{{}}{{}}}
\bibcite{DBLP:journals/corr/MrksicSWTY16}{{48}{}{{}}{{}}}
\bibcite{DBLP:journals/corr/abs-1711-01731}{{49}{}{{}}{{}}}
\bibcite{henderson_interdomain}{{50}{}{{}}{{}}}
\bibcite{lopez-cozar-simulation}{{51}{}{{}}{{}}}
\bibcite{Schatzmann_stat_user_sim}{{52}{}{{}}{{}}}
\bibcite{Chung_user_sim}{{53}{}{{}}{{}}}
\bibcite{Lopez-Cozar_user-sim}{{54}{}{{}}{{}}}
\bibcite{Cuayhuitl2006LearningMD}{{55}{}{{}}{{}}}
\bibcite{levin_mdp}{{56}{}{{}}{{}}}
\bibcite{4430164}{{57}{}{{}}{{}}}
\bibcite{Georgila2006UserSF}{{58}{}{{}}{{}}}
\bibcite{Cuayhuitl2005HumancomputerDS}{{59}{}{{}}{{}}}
\bibcite{Scheffler_sim}{{60}{}{{}}{{}}}
\bibcite{Schatzmann2007StatisticalUS}{{61}{}{{}}{{}}}
\bibcite{georgila1998integrated}{{62}{}{{}}{{}}}
\bibcite{chai2001natural}{{63}{}{{}}{{}}}
\bibcite{su2013dialoguegame}{{64}{}{{}}{{}}}
\bibcite{ELVIS}{{65}{}{{}}{{}}}
\bibcite{Shriver_unified}{{66}{}{{}}{{}}}
\bibcite{TRAIN}{{67}{}{{}}{{}}}
\bibcite{ferguson1998trips}{{68}{}{{}}{{}}}
\bibcite{Levin97astochastic}{{69}{}{{}}{{}}}
\bibcite{rl_overview}{{70}{}{{}}{{}}}
\bibcite{sutton1988TFDearning}{{71}{}{{}}{{}}}
\bibcite{watkins1989Qlearning}{{72}{}{{}}{{}}}
\bibcite{adam2012experience}{{73}{}{{}}{{}}}
\bibcite{verleysen2005curse}{{74}{}{{}}{{}}}
\bibcite{hornik1989multilayer}{{75}{}{{}}{{}}}
\bibcite{peters2005natural}{{76}{}{{}}{{}}}
\bibcite{bordes2016learning}{{77}{}{{}}{{}}}
\bibcite{liu2016not}{{78}{}{{}}{{}}}
\bibcite{Williams:2007:POM:1221595.1221967}{{79}{}{{}}{{}}}
\bibcite{lemon2006evaluating}{{80}{}{{}}{{}}}
\bibcite{walker1997paradise}{{81}{}{{}}{{}}}
\bibcite{larsen2003issues}{{82}{}{{}}{{}}}
\bibcite{mataric1994reward}{{83}{}{{}}{{}}}
\bibcite{ng1999policy}{{84}{}{{}}{{}}}
\bibcite{Goodfellow-et-al-2016}{{85}{}{{}}{{}}}
\bibcite{LeCun:1998:CNI:303568.303704}{{86}{}{{}}{{}}}
\bibcite{jarrett2009best}{{87}{}{{}}{{}}}
\bibcite{maas2013rectifier}{{88}{}{{}}{{}}}
\bibcite{he2015delving}{{89}{}{{}}{{}}}
\bibcite{cauchy1847methode}{{90}{}{{}}{{}}}
\bibcite{rumelhart1986learning}{{91}{}{{}}{{}}}
\bibcite{Williams92REINFORCE}{{92}{}{{}}{{}}}
\bibcite{kingma2014adam}{{93}{}{{}}{{}}}
\bibcite{python}{{94}{}{{}}{{}}}
\bibcite{keras}{{95}{}{{}}{{}}}
\bibcite{walker2000evaluation}{{96}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
