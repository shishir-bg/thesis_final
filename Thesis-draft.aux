\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{ieeetr}
\providecommand \oddpage@label [2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\newlabel{cover2}{{}{2}{}{Doc-Start}{}}
\citation{Sutton-introRL}
\citation{Goodfellow-et-al-2016}
\citation{macwhinne_lang_evol}
\citation{turing_mind}
\citation{kurzweil_sing}
\citation{Weizenbaum:1966:ECP:365153.365168}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{9}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Overview}{9}{subsection.1.1}}
\citation{ncf2017}
\citation{frey2017future}
\citation{Tao_of_CHI}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Motivation}{10}{subsection.1.2}}
\newlabel{plag1}{{1.2}{10}{Motivation}{subsection.1.2}{}}
\newlabel{plag10}{{1.2}{10}{Motivation}{subsection.1.2}{}}
\citation{zue_jupiter}
\citation{Larsson:2000:ISD:973935.973943}
\citation{mdp-bellmann}
\citation{mdp-pieraccini}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}State of the Art}{11}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Dialog Policy trained with Reinforcement Learning}{11}{subsubsection.1.3.1}}
\citation{Young99probabilisticmethods}
\citation{Singh_mdp}
\citation{Pietquin_mdp}
\citation{Dhingra2016EndtoEndRL}
\citation{Cuayhuitl2016SimpleDSAS}
\citation{Li17e2eDS}
\citation{HakkaniTr2016NLU}
\citation{Wen_NLG}
\citation{hochreiter1997long}
\citation{Schatzmann_agenda_sim}
\citation{Li_user_sim}
\citation{Mnih_DQN}
\citation{tensorflow}
\citation{Sutskever_seq_2seq}
\citation{karpathy_rnn}
\citation{hochreiter1998vanishing}
\citation{hochreiter1997long}
\citation{Sukhbaatar_end2end_mem_net}
\citation{babl}
\citation{bordes_weston_e2e}
\citation{Su_continous_dm}
\citation{Schulman_trpo}
\citation{Sutton_pg}
\citation{Lin1992}
\citation{Williams_HCN_e2e}
\citation{Sutton_pg}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Dialog Policy trained with End-to-End Supervised Learning}{13}{subsubsection.1.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Dialog Policy trained with a Combined Approach}{14}{subsubsection.1.3.3}}
\citation{mdp-pieraccini}
\citation{ds_survey}
\citation{Pieraccini2006WhereDW}
\citation{ml_dst_review}
\@writefile{toc}{\contentsline {section}{\numberline {2}Dialog Systems}{15}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overview}{15}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}System Architecture}{15}{subsection.2.2}}
\newlabel{subsec:sys-arch}{{2.2}{15}{System Architecture}{subsection.2.2}{}}
\citation{mdp-bellmann}
\citation{mdp-pieraccini}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Text Based Dialog System Architecture }}{16}{figure.1}}
\newlabel{sys-arch1}{{1}{16}{Text Based Dialog System Architecture}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Dialog Management}{16}{subsection.2.3}}
\citation{Sutton-introRL}
\citation{Larsson:2000:ISD:973935.973943}
\citation{Young_dst_dbn}
\citation{roy2000spoken}
\citation{Henderson:2008:MMP:1557690.1557710}
\citation{Young:2010:HIS:1621140.1621240}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Dialog State Tracking (DST)}{17}{subsubsection.2.3.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.1}Information State DST}{17}{paragraph.2.3.1.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.2}Generative DST}{17}{paragraph.2.3.1.2}}
\citation{generative_dst_limitation}
\citation{Lee2013StructuredDM}
\citation{Henderson2014WordBasedDS}
\citation{Henderson_dst_2014}
\citation{DBLP:journals/corr/MrksicSWTY16}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.3}Discriminative DST}{18}{paragraph.2.3.1.3}}
\citation{Sutton-introRL}
\citation{Larsson:2000:ISD:973935.973943}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\citation{DBLP:journals/corr/abs-1711-01731}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.4}Our Approach}{19}{paragraph.2.3.1.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Dialog Policy}{19}{subsubsection.2.3.2}}
\citation{henderson_interdomain}
\citation{mdp-pieraccini}
\citation{lopez-cozar-simulation}
\citation{Schatzmann_stat_user_sim}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.2.1}Our Approach}{20}{paragraph.2.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}User Simulation}{20}{subsection.2.4}}
\citation{Chung_user_sim}
\citation{Lopez-Cozar_user-sim}
\citation{Cuayhuitl2006LearningMD}
\citation{levin_mdp}
\citation{4430164}
\citation{Georgila2006UserSF}
\citation{Cuayhuitl2005HumancomputerDS}
\citation{Scheffler_sim}
\citation{Schatzmann2007StatisticalUS}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Rule Based Simulation}{21}{subsubsection.2.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Probabilistic Model Based Simulation}{21}{subsubsection.2.4.2}}
\citation{Scheffler_sim}
\citation{georgila1998integrated}
\citation{chai2001natural}
\citation{su2013dialoguegame}
\citation{ELVIS}
\citation{zue_jupiter}
\citation{Shriver_unified}
\citation{TRAIN}
\citation{ferguson1998trips}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Our Approach}{22}{subsubsection.2.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Applications}{22}{subsection.2.5}}
\citation{Levin97astochastic}
\citation{Levin97astochastic}
\citation{mdp-pieraccini}
\@writefile{toc}{\contentsline {section}{\numberline {3}Technical Background}{24}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overview}{24}{subsection.3.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Reinforcement Learning (RL)}{24}{subsection.3.2}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Agent-Environment Interface \cite  {Sutton-introRL} }}{26}{figure.2}}
\newlabel{agent-env-rl}{{2}{26}{Agent-Environment Interface \cite {Sutton-introRL}}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Markov Decision Processes (MDP)}{26}{subsection.3.3}}
\newlabel{subsec:mdp}{{3.3}{26}{Markov Decision Processes (MDP)}{subsection.3.3}{}}
\citation{Sutton-introRL}
\newlabel{eq:1}{{3.1}{27}{Markov Decision Processes (MDP)}{equation.3.1}{}}
\newlabel{eq:2}{{3.2}{27}{Markov Decision Processes (MDP)}{equation.3.2}{}}
\newlabel{eq:3}{{3.3}{27}{Markov Decision Processes (MDP)}{equation.3.3}{}}
\newlabel{eq:4}{{3.4}{27}{Markov Decision Processes (MDP)}{equation.3.4}{}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\newlabel{eq:5}{{3.5}{28}{Markov Decision Processes (MDP)}{equation.3.5}{}}
\newlabel{eq:6}{{3.6}{28}{Markov Decision Processes (MDP)}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Optimality}{28}{subsubsection.3.3.1}}
\newlabel{optimality}{{3.3.1}{28}{Optimality}{subsubsection.3.3.1}{}}
\citation{Sutton-introRL}
\citation{Young99probabilisticmethods}
\citation{mdp-pieraccini}
\citation{mdp-bellmann}
\citation{Sutton-introRL}
\newlabel{eq:7}{{3.8}{29}{Optimality}{equation.3.8}{}}
\newlabel{eq:8}{{3.9}{29}{Optimality}{equation.3.9}{}}
\newlabel{eq:9}{{3.10}{29}{Optimality}{equation.3.10}{}}
\newlabel{eq:10}{{3.11}{29}{Optimality}{equation.3.11}{}}
\newlabel{eq:11}{{3.12}{29}{Optimality}{equation.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Composing Dialog Management as an MDP}{30}{subsection.3.4}}
\newlabel{dialog-mdp}{{3.4}{30}{Composing Dialog Management as an MDP}{subsection.3.4}{}}
\citation{Larsson:2000:ISD:973935.973943}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Dialog represented as a Markov Decision Process }}{31}{figure.3}}
\newlabel{chat-world3}{{3}{31}{Dialog represented as a Markov Decision Process}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Agent-Environment Interaction }}{33}{figure.4}}
\newlabel{chat-world}{{4}{33}{Agent-Environment Interaction}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Agent-Environment Interaction in the form of a chatbot application }}{34}{figure.5}}
\newlabel{chat-world2}{{5}{34}{Agent-Environment Interaction in the form of a chatbot application}{figure.5}{}}
\citation{rl_overview}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Policy Optimization}{35}{subsection.3.5}}
\newlabel{policy-opt}{{3.5}{35}{Policy Optimization}{subsection.3.5}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Dialog Policy Optimization Methods }}{35}{figure.6}}
\newlabel{mdp-methods}{{6}{35}{Dialog Policy Optimization Methods}{figure.6}{}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Value Iterative Methods}{36}{subsubsection.3.5.1}}
\newlabel{eq:12}{{3.13}{36}{Value Iterative Methods}{equation.3.13}{}}
\newlabel{eq:13}{{3.14}{36}{Value Iterative Methods}{equation.3.14}{}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.1}Dynamic Programming}{37}{paragraph.3.5.1.1}}
\newlabel{dp}{{3.5.1.1}{37}{Dynamic Programming}{paragraph.3.5.1.1}{}}
\newlabel{eq:dp-update}{{3.15}{37}{Dynamic Programming}{equation.3.15}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.2}Monte Carlo Learning }{37}{paragraph.3.5.1.2}}
\newlabel{mc-learning}{{3.5.1.2}{37}{Monte Carlo Learning}{paragraph.3.5.1.2}{}}
\citation{sutton1988TFDearning}
\citation{sutton1988TFDearning}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.3}Temporal Difference(TD) Learning }{38}{paragraph.3.5.1.3}}
\newlabel{td-learning}{{3.5.1.3}{38}{Temporal Difference(TD) Learning}{paragraph.3.5.1.3}{}}
\newlabel{eq:td-error}{{3.16}{38}{Temporal Difference(TD) Learning}{equation.3.16}{}}
\newlabel{eq:td-update}{{3.17}{38}{Temporal Difference(TD) Learning}{equation.3.17}{}}
\citation{watkins1989Qlearning}
\newlabel{eq:sarsa-update}{{3.18}{39}{Temporal Difference(TD) Learning}{equation.3.18}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces SARSA}}{39}{algocf.1}}
\newlabel{alg:sarsa}{{1}{39}{Temporal Difference(TD) Learning}{algocf.1}{}}
\newlabel{eq:q-update}{{3.19}{39}{Temporal Difference(TD) Learning}{equation.3.19}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.4}Sample Efficiency}{39}{paragraph.3.5.1.4}}
\citation{adam2012experience}
\citation{verleysen2005curse}
\citation{hornik1989multilayer}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Q-Learning}}{40}{algocf.2}}
\newlabel{alg:q-learning}{{2}{40}{Temporal Difference(TD) Learning}{algocf.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.5}Function Approximation}{41}{paragraph.3.5.1.5}}
\newlabel{fn_aprrox}{{3.5.1.5}{41}{Function Approximation}{paragraph.3.5.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Policy Iterative Methods}{41}{subsubsection.3.5.2}}
\newlabel{policy_methods}{{3.5.2}{41}{Policy Iterative Methods}{subsubsection.3.5.2}{}}
\citation{Sutton-introRL}
\newlabel{eq:17}{{3.25}{42}{Policy Iterative Methods}{equation.3.25}{}}
\citation{Sutton-introRL}
\citation{Sutton_pg}
\newlabel{eq:obj_value}{{3.28}{43}{Policy Iterative Methods}{equation.3.28}{}}
\citation{Sutton-introRL}
\citation{Sutton_pg}
\newlabel{eq:vpg_update}{{3.30}{44}{Policy Iterative Methods}{equation.3.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Actor-Critic Methods}{44}{subsubsection.3.5.3}}
\newlabel{section:ac-methods}{{3.5.3}{44}{Actor-Critic Methods}{subsubsection.3.5.3}{}}
\newlabel{eq:pg-theorem}{{3.31}{44}{Actor-Critic Methods}{equation.3.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Actor-Critic Environment Interaction }}{45}{figure.7}}
\newlabel{a-c}{{7}{45}{Actor-Critic Environment Interaction}{figure.7}{}}
\newlabel{eq:ac-conv}{{3.32}{45}{Actor-Critic Methods}{equation.3.32}{}}
\newlabel{eq:pg-compatible}{{3.33}{45}{Actor-Critic Methods}{equation.3.33}{}}
\newlabel{eq:ac-error}{{3.34}{45}{Actor-Critic Methods}{equation.3.34}{}}
\newlabel{eq:pg-f}{{3.35}{45}{Actor-Critic Methods}{equation.3.35}{}}
\citation{peters2005natural}
\citation{Sutton_pg}
\citation{peters2005natural}
\citation{Sutton_pg}
\citation{bordes2016learning}
\citation{liu2016not}
\citation{Williams:2007:POM:1221595.1221967}
\citation{DBLP:journals/corr/abs-1711-01731}
\citation{lemon2006evaluating}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Evaluation and Reward Estimation}{46}{subsection.3.6}}
\citation{walker1997paradise}
\citation{larsen2003issues}
\citation{mataric1994reward}
\citation{ng1999policy}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Heuristic Rewards}{47}{subsubsection.3.6.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}The Paradise Framework}{47}{subsubsection.3.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Reward Shaping}{47}{subsubsection.3.6.3}}
\citation{Sutton-introRL}
\newlabel{eg:reward-shaping-condition}{{3.38}{48}{Reward Shaping}{equation.3.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Auxiliary RL terminology}{48}{subsection.3.7}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1}Model-based and Model-free}{49}{subsubsection.3.7.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.2}Episodic and Continuous Tasks}{49}{subsubsection.3.7.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.3}On-line and Off-line}{49}{subsubsection.3.7.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.4}On Policy and Off Policy}{50}{subsubsection.3.7.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.5}Exploration and Exploitation}{50}{subsubsection.3.7.5}}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {section}{\numberline {4}Deep Learning}{51}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Overview}{51}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Deep Feedforward Networks}{51}{subsection.4.2}}
\citation{LeCun:1998:CNI:303568.303704}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Loss Functions}{52}{subsection.4.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Fully Connected Neural Network }}{53}{figure.8}}
\newlabel{nn-fully-connected}{{8}{53}{Fully Connected Neural Network}{figure.8}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Maximum Likelihood Estimation}{53}{subsubsection.4.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Approximating Conditional Distributions with Maximum Likelihood}{54}{subsubsection.4.3.2}}
\newlabel{eq:mse_loss}{{4.7}{55}{Approximating Conditional Distributions with Maximum Likelihood}{equation.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Output Units}{55}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Linear Units}{55}{subsubsection.4.4.1}}
\newlabel{linear_unit}{{4.4.1}{55}{Linear Units}{subsubsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Sigmoid Units}{55}{subsubsection.4.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Softmax Units}{56}{subsubsection.4.4.3}}
\newlabel{softmax}{{4.4.3}{56}{Softmax Units}{subsubsection.4.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Hidden Units}{57}{subsection.4.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Rectified Linear Units(ReLU)}{57}{subsubsection.4.5.1}}
\citation{jarrett2009best}
\citation{maas2013rectifier}
\citation{he2015delving}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Rectified Linear Unit }}{58}{figure.9}}
\newlabel{relu}{{9}{58}{Rectified Linear Unit}{figure.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}The Hyperbolic Tangent and Logistic Sigmoid}{58}{subsubsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Logistic Sigmoid Unit }}{59}{figure.10}}
\newlabel{sigmoid}{{10}{59}{Logistic Sigmoid Unit}{figure.10}{}}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Hyperbolic Tangent Unit }}{60}{figure.11}}
\newlabel{tanh}{{11}{60}{Hyperbolic Tangent Unit}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Architecture}{60}{subsection.4.6}}
\citation{Goodfellow-et-al-2016}
\citation{cauchy1847methode}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces General Architecture of a Neural Network }}{61}{figure.12}}
\newlabel{nn_arch}{{12}{61}{General Architecture of a Neural Network}{figure.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Gradient Based Learning}{61}{subsection.4.7}}
\citation{rumelhart1986learning}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The Process of Gradient Descent\cite  {Goodfellow-et-al-2016} }}{62}{figure.13}}
\newlabel{grad_descent}{{13}{62}{The Process of Gradient Descent\cite {Goodfellow-et-al-2016}}{figure.13}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.1}Back-Propagation}{62}{subsubsection.4.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Back Propagating Errors Through a Neural Network }}{63}{figure.14}}
\newlabel{back_prop}{{14}{63}{Back Propagating Errors Through a Neural Network}{figure.14}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Forward Propagation through a deep neural network and the loss computation}}{64}{algocf.3}}
\newlabel{alg:forward-prop}{{3}{64}{Back-Propagation}{algocf.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.2}Stochastic Gradient Descent(SGD)}{64}{subsubsection.4.7.2}}
\newlabel{sgd}{{4.7.2}{64}{Stochastic Gradient Descent(SGD)}{subsubsection.4.7.2}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Back Propagation}}{65}{algocf.4}}
\newlabel{alg:back-prop}{{4}{65}{Back-Propagation}{algocf.4}{}}
\citation{Williams92REINFORCE}
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Stochastic Gradient Descent Algorithm}}{66}{algocf.5}}
\newlabel{alg:sgd}{{5}{66}{Stochastic Gradient Descent(SGD)}{algocf.5}{}}
\@writefile{toc}{\contentsline {section}{\numberline {5}Neural Dialog Management}{66}{section.5}}
\newlabel{dm-with-drl}{{5}{66}{Neural Dialog Management}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Overview}{66}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}REINFORCE}{66}{subsection.5.2}}
\newlabel{eq:pg-expectation}{{5.1}{67}{REINFORCE}{equation.5.1}{}}
\newlabel{eq:reinforce-update}{{5.4}{67}{REINFORCE}{equation.5.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}REINFORCE Algorithm}{68}{subsubsection.5.2.1}}
\newlabel{reinforce}{{5.2.1}{68}{REINFORCE Algorithm}{subsubsection.5.2.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces REINFORCE}}{68}{algocf.6}}
\newlabel{alg:reinforce}{{6}{68}{REINFORCE Algorithm}{algocf.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Policy Network}{68}{subsubsection.5.2.2}}
\citation{kingma2014adam}
\citation{Sutton_pg}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Policy Neural Network }}{69}{figure.15}}
\newlabel{nn-policy}{{15}{69}{Policy Neural Network}{figure.15}{}}
\citation{Sutton_pg}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Advantage Actor Critic}{70}{subsection.5.3}}
\newlabel{a2c-section}{{5.3}{70}{Advantage Actor Critic}{subsection.5.3}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Advantage Function}{70}{subsubsection.5.3.1}}
\newlabel{eq:baseline}{{5.5}{70}{Advantage Function}{equation.5.5}{}}
\newlabel{eq:adv}{{5.6}{71}{Advantage Function}{equation.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Actor-Critic Environment Interaction }}{71}{figure.16}}
\newlabel{a2c}{{16}{71}{Actor-Critic Environment Interaction}{figure.16}{}}
\citation{Williams92REINFORCE}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}A2C Algorithm}{72}{subsubsection.5.3.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Actor Network}{72}{subsubsection.5.3.3}}
\citation{kingma2014adam}
\@writefile{loa}{\contentsline {algocf}{\numberline {7}{\ignorespaces Advantage Actor Critic Algorithm}}{73}{algocf.7}}
\newlabel{alg:a2c}{{7}{73}{A2C Algorithm}{algocf.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Actor Network }}{74}{figure.17}}
\newlabel{nn-actor}{{17}{74}{Actor Network}{figure.17}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Critic Network}{74}{subsubsection.5.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Critic Network }}{75}{figure.18}}
\newlabel{nn-critic}{{18}{75}{Critic Network}{figure.18}{}}
\citation{python}
\citation{tensorflow}
\citation{keras}
\citation{Singh_mdp}
\citation{walker2000evaluation}
\citation{roy2000spoken}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments and Results}{76}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Overview}{76}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Learning Simple Dialog Strategies}{76}{subsection.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Experimental Setup}{76}{subsubsection.6.2.1}}
\newlabel{expt-setup}{{6.2.1}{76}{Experimental Setup}{subsubsection.6.2.1}{}}
\citation{Larsson:2000:ISD:973935.973943}
\newlabel{eq:trans-prob1}{{6.1}{77}{Experimental Setup}{equation.6.1}{}}
\newlabel{eq:trans-prob2}{{6.2}{77}{Experimental Setup}{equation.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces State Transition Model }}{78}{figure.19}}
\newlabel{state-trans}{{19}{78}{State Transition Model}{figure.19}{}}
\newlabel{eq:trans-prob3}{{6.5}{79}{Experimental Setup}{equation.6.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces User Simulation Model}}{79}{table.1}}
\newlabel{table:user-sim}{{1}{79}{User Simulation Model}{table.1}{}}
\newlabel{reward_func}{{6.6}{80}{Experimental Setup}{equation.6.6}{}}
\citation{Sutton-introRL}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces System Actions}}{81}{table.2}}
\newlabel{table:actions}{{2}{81}{System Actions}{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Learning with A2C}{81}{subsubsection.6.2.2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.1}Results}{82}{paragraph.6.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces A2C Learning Curve }}{83}{figure.20}}
\newlabel{a2c-plot}{{20}{83}{A2C Learning Curve}{figure.20}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.2}Effect of the Discount Factor}{84}{paragraph.6.2.2.2}}
\newlabel{a2c_df_effect}{{6.2.2.2}{84}{Effect of the Discount Factor}{paragraph.6.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Effect of the Discount Factor on A2C Learning }}{85}{figure.21}}
\newlabel{a2c_dis_fact}{{21}{85}{Effect of the Discount Factor on A2C Learning}{figure.21}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.3}Effect of Reward Magnitude}{86}{paragraph.6.2.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Effect of the Absolute Reward Magnitude on A2C Learning }}{87}{figure.22}}
\newlabel{a2c_reward_mag}{{22}{87}{Effect of the Absolute Reward Magnitude on A2C Learning}{figure.22}{}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}Learning with REINFORCE}{88}{subsubsection.6.2.3}}
\newlabel{reward_func_10}{{6.7}{88}{Learning with REINFORCE}{equation.6.7}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.3.1}Results}{88}{paragraph.6.2.3.1}}
\newlabel{reinf_pre_results}{{6.2.3.1}{88}{Results}{paragraph.6.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces REINFORCE Learning Curve }}{89}{figure.23}}
\newlabel{reinforce-plot}{{23}{89}{REINFORCE Learning Curve}{figure.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Summary}{90}{subsection.6.3}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{92}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Conclusion}{92}{subsection.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Future Work}{92}{subsection.7.2}}
\newlabel{my-label}{{7.2}{94}{Abbreviations}{section*.8}{}}
\bibstyle{apa}
\bibdata{references}
\bibcite{macwhinne_lang_evol}{{1}{}{{}}{{}}}
\bibcite{turing_mind}{{2}{}{{}}{{}}}
\bibcite{kurzweil_sing}{{3}{}{{}}{{}}}
\bibcite{Weizenbaum:1966:ECP:365153.365168}{{4}{}{{}}{{}}}
\bibcite{ncf2017}{{5}{}{{}}{{}}}
\bibcite{frey2017future}{{6}{}{{}}{{}}}
\bibcite{Tao_of_CHI}{{7}{}{{}}{{}}}
\bibcite{zue_jupiter}{{8}{}{{}}{{}}}
\bibcite{Larsson:2000:ISD:973935.973943}{{9}{}{{}}{{}}}
\bibcite{mdp-bellmann}{{10}{}{{}}{{}}}
\bibcite{mdp-pieraccini}{{11}{}{{}}{{}}}
\bibcite{Young99probabilisticmethods}{{12}{}{{}}{{}}}
\bibcite{Singh_mdp}{{13}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {8}References}{95}{section.8}}
\bibcite{Pietquin_mdp}{{14}{}{{}}{{}}}
\bibcite{Dhingra2016EndtoEndRL}{{15}{}{{}}{{}}}
\bibcite{Cuayhuitl2016SimpleDSAS}{{16}{}{{}}{{}}}
\bibcite{Li17e2eDS}{{17}{}{{}}{{}}}
\bibcite{HakkaniTr2016NLU}{{18}{}{{}}{{}}}
\bibcite{Wen_NLG}{{19}{}{{}}{{}}}
\bibcite{hochreiter1997long}{{20}{}{{}}{{}}}
\bibcite{Schatzmann_agenda_sim}{{21}{}{{}}{{}}}
\bibcite{Li_user_sim}{{22}{}{{}}{{}}}
\bibcite{Mnih_DQN}{{23}{}{{}}{{}}}
\bibcite{tensorflow}{{24}{}{{}}{{}}}
\bibcite{Sutskever_seq_2seq}{{25}{}{{}}{{}}}
\bibcite{karpathy_rnn}{{26}{}{{}}{{}}}
\bibcite{hochreiter1998vanishing}{{27}{}{{}}{{}}}
\bibcite{Sukhbaatar_end2end_mem_net}{{28}{}{{}}{{}}}
\bibcite{babl}{{29}{}{{}}{{}}}
\bibcite{bordes_weston_e2e}{{30}{}{{}}{{}}}
\bibcite{Su_continous_dm}{{31}{}{{}}{{}}}
\bibcite{Schulman_trpo}{{32}{}{{}}{{}}}
\bibcite{Sutton_pg}{{33}{}{{}}{{}}}
\bibcite{Lin1992}{{34}{}{{}}{{}}}
\bibcite{Williams_HCN_e2e}{{35}{}{{}}{{}}}
\bibcite{ds_survey}{{36}{}{{}}{{}}}
\bibcite{Pieraccini2006WhereDW}{{37}{}{{}}{{}}}
\bibcite{ml_dst_review}{{38}{}{{}}{{}}}
\bibcite{Sutton-introRL}{{39}{}{{}}{{}}}
\bibcite{Young_dst_dbn}{{40}{}{{}}{{}}}
\bibcite{roy2000spoken}{{41}{}{{}}{{}}}
\bibcite{Henderson:2008:MMP:1557690.1557710}{{42}{}{{}}{{}}}
\bibcite{Young:2010:HIS:1621140.1621240}{{43}{}{{}}{{}}}
\bibcite{generative_dst_limitation}{{44}{}{{}}{{}}}
\bibcite{Lee2013StructuredDM}{{45}{}{{}}{{}}}
\bibcite{Henderson2014WordBasedDS}{{46}{}{{}}{{}}}
\bibcite{Henderson_dst_2014}{{47}{}{{}}{{}}}
\bibcite{DBLP:journals/corr/MrksicSWTY16}{{48}{}{{}}{{}}}
\bibcite{DBLP:journals/corr/abs-1711-01731}{{49}{}{{}}{{}}}
\bibcite{henderson_interdomain}{{50}{}{{}}{{}}}
\bibcite{lopez-cozar-simulation}{{51}{}{{}}{{}}}
\bibcite{Schatzmann_stat_user_sim}{{52}{}{{}}{{}}}
\bibcite{Chung_user_sim}{{53}{}{{}}{{}}}
\bibcite{Lopez-Cozar_user-sim}{{54}{}{{}}{{}}}
\bibcite{Cuayhuitl2006LearningMD}{{55}{}{{}}{{}}}
\bibcite{levin_mdp}{{56}{}{{}}{{}}}
\bibcite{4430164}{{57}{}{{}}{{}}}
\bibcite{Georgila2006UserSF}{{58}{}{{}}{{}}}
\bibcite{Cuayhuitl2005HumancomputerDS}{{59}{}{{}}{{}}}
\bibcite{Scheffler_sim}{{60}{}{{}}{{}}}
\bibcite{Schatzmann2007StatisticalUS}{{61}{}{{}}{{}}}
\bibcite{georgila1998integrated}{{62}{}{{}}{{}}}
\bibcite{chai2001natural}{{63}{}{{}}{{}}}
\bibcite{su2013dialoguegame}{{64}{}{{}}{{}}}
\bibcite{ELVIS}{{65}{}{{}}{{}}}
\bibcite{Shriver_unified}{{66}{}{{}}{{}}}
\bibcite{TRAIN}{{67}{}{{}}{{}}}
\bibcite{ferguson1998trips}{{68}{}{{}}{{}}}
\bibcite{Levin97astochastic}{{69}{}{{}}{{}}}
\bibcite{rl_overview}{{70}{}{{}}{{}}}
\bibcite{sutton1988TFDearning}{{71}{}{{}}{{}}}
\bibcite{watkins1989Qlearning}{{72}{}{{}}{{}}}
\bibcite{adam2012experience}{{73}{}{{}}{{}}}
\bibcite{verleysen2005curse}{{74}{}{{}}{{}}}
\bibcite{hornik1989multilayer}{{75}{}{{}}{{}}}
\bibcite{peters2005natural}{{76}{}{{}}{{}}}
\bibcite{bordes2016learning}{{77}{}{{}}{{}}}
\bibcite{liu2016not}{{78}{}{{}}{{}}}
\bibcite{Williams:2007:POM:1221595.1221967}{{79}{}{{}}{{}}}
\bibcite{lemon2006evaluating}{{80}{}{{}}{{}}}
\bibcite{walker1997paradise}{{81}{}{{}}{{}}}
\bibcite{larsen2003issues}{{82}{}{{}}{{}}}
\bibcite{mataric1994reward}{{83}{}{{}}{{}}}
\bibcite{ng1999policy}{{84}{}{{}}{{}}}
\bibcite{Goodfellow-et-al-2016}{{85}{}{{}}{{}}}
\bibcite{LeCun:1998:CNI:303568.303704}{{86}{}{{}}{{}}}
\bibcite{jarrett2009best}{{87}{}{{}}{{}}}
\bibcite{maas2013rectifier}{{88}{}{{}}{{}}}
\bibcite{he2015delving}{{89}{}{{}}{{}}}
\bibcite{cauchy1847methode}{{90}{}{{}}{{}}}
\bibcite{rumelhart1986learning}{{91}{}{{}}{{}}}
\bibcite{Williams92REINFORCE}{{92}{}{{}}{{}}}
\bibcite{kingma2014adam}{{93}{}{{}}{{}}}
\bibcite{python}{{94}{}{{}}{{}}}
\bibcite{keras}{{95}{}{{}}{{}}}
\bibcite{walker2000evaluation}{{96}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
