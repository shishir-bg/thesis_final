\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\bibstyle{ieeetr}
\providecommand \oddpage@label [2]{}
\select@language{english}
\@writefile{toc}{\select@language{english}}
\@writefile{lof}{\select@language{english}}
\@writefile{lot}{\select@language{english}}
\citation{Sutton-introRL}
\citation{Goodfellow-et-al-2016}
\citation{macwhinne_lang_evol}
\citation{turing_mind}
\citation{kurzweil_sing}
\citation{Weizenbaum:1966:ECP:365153.365168}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{10}{section.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}Overview}{10}{subsection.1.1}}
\citation{ncf2017}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}Motivation}{11}{subsection.1.2}}
\citation{frey2017future}
\citation{Tao_of_CHI}
\newlabel{plag1}{{1.2}{12}{Motivation}{subsection.1.2}{}}
\newlabel{plag10}{{1.2}{12}{Motivation}{subsection.1.2}{}}
\citation{zue_jupiter}
\citation{Larsson:2000:ISD:973935.973943}
\citation{mdp-bellmann}
\citation{mdp-pieraccini}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.3}State of the Art}{13}{subsection.1.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.1}Dialog Policy trained with Reinforcement Learning}{13}{subsubsection.1.3.1}}
\citation{Young99probabilisticmethods}
\citation{Singh_mdp}
\citation{Pietquin_mdp}
\citation{Dhingra2016EndtoEndRL}
\citation{Cuayhuitl2016SimpleDSAS}
\citation{Li17e2eDS}
\citation{HakkaniTr2016NLU}
\citation{Wen_NLG}
\citation{hochreiter1997long}
\citation{Schatzmann_agenda_sim}
\citation{Li_user_sim}
\citation{Mnih_DQN}
\citation{tensorflow}
\citation{Sutskever_seq_2seq}
\citation{karpathy_rnn}
\citation{hochreiter1998vanishing}
\citation{hochreiter1997long}
\citation{Sukhbaatar_end2end_mem_net}
\citation{babl}
\citation{bordes_weston_e2e}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.2}Dialog Policy trained with End-to-End Supervised Learning}{15}{subsubsection.1.3.2}}
\citation{Su_continous_dm}
\citation{Schulman_trpo}
\citation{Sutton_pg}
\citation{Lin1992}
\citation{Williams_HCN_e2e}
\citation{Sutton_pg}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {1.3.3}Dialog Policy trained with a Combined Approach}{16}{subsubsection.1.3.3}}
\citation{mdp-pieraccini}
\citation{ds_survey}
\citation{Pieraccini2006WhereDW}
\citation{ml_dst_review}
\@writefile{toc}{\contentsline {section}{\numberline {2}Dialog Systems}{18}{section.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Overview}{18}{subsection.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}System Architecture}{18}{subsection.2.2}}
\newlabel{subsec:sys-arch}{{2.2}{18}{System Architecture}{subsection.2.2}{}}
\citation{mdp-bellmann}
\citation{mdp-pieraccini}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Text Based Dialog System Architecture }}{20}{figure.1}}
\newlabel{sys-arch1}{{1}{20}{Text Based Dialog System Architecture}{figure.1}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Dialog Management}{20}{subsection.2.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.1}Dialog State Tracking (DST)}{20}{subsubsection.2.3.1}}
\citation{Sutton-introRL}
\citation{Larsson:2000:ISD:973935.973943}
\citation{Young_dst_dbn}
\citation{roy2000spoken}
\citation{Henderson:2008:MMP:1557690.1557710}
\citation{Young:2010:HIS:1621140.1621240}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.1}Information State DST}{21}{paragraph.2.3.1.1}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.2}Generative DST}{21}{paragraph.2.3.1.2}}
\citation{generative_dst_limitation}
\citation{Lee2013StructuredDM}
\citation{Henderson2014WordBasedDS}
\citation{Henderson_dst_2014}
\citation{DBLP:journals/corr/MrksicSWTY16}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.3}Discriminative DST}{22}{paragraph.2.3.1.3}}
\citation{Sutton-introRL}
\citation{Larsson:2000:ISD:973935.973943}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.1.4}Our Approach}{23}{paragraph.2.3.1.4}}
\citation{Sutton-introRL}
\citation{DBLP:journals/corr/abs-1711-01731}
\citation{henderson_interdomain}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.3.2}Dialog Policy}{24}{subsubsection.2.3.2}}
\citation{mdp-pieraccini}
\citation{lopez-cozar-simulation}
\citation{Schatzmann_stat_user_sim}
\@writefile{toc}{\contentsline {paragraph}{\numberline {2.3.2.1}Our Approach}{25}{paragraph.2.3.2.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}User Simulation}{25}{subsection.2.4}}
\citation{Chung_user_sim}
\citation{Lopez-Cozar_user-sim}
\citation{Cuayhuitl2006LearningMD}
\citation{levin_mdp}
\citation{4430164}
\citation{Georgila2006UserSF}
\citation{Cuayhuitl2005HumancomputerDS}
\citation{Scheffler_sim}
\citation{Schatzmann2007StatisticalUS}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.1}Rule Based Simulation}{26}{subsubsection.2.4.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.2}Probabilistic Model Based Simulation}{26}{subsubsection.2.4.2}}
\citation{Scheffler_sim}
\citation{georgila1998integrated}
\citation{chai2001natural}
\citation{su2013dialoguegame}
\citation{ELVIS}
\citation{zue_jupiter}
\citation{Shriver_unified}
\citation{TRAIN}
\citation{ferguson1998trips}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {2.4.3}Our Approach}{27}{subsubsection.2.4.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.5}Applications}{28}{subsection.2.5}}
\citation{Levin97astochastic}
\citation{Levin97astochastic}
\citation{mdp-pieraccini}
\@writefile{toc}{\contentsline {section}{\numberline {3}Technical Background}{29}{section.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.1}Overview}{29}{subsection.3.1}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.2}Reinforcement Learning (RL)}{30}{subsection.3.2}}
\citation{Sutton-introRL}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Agent-Environment Interface \cite  {Sutton-introRL} }}{31}{figure.2}}
\newlabel{agent-env-rl}{{2}{31}{Agent-Environment Interface \cite {Sutton-introRL}}{figure.2}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.3}Markov Decision Processes (MDP)}{31}{subsection.3.3}}
\newlabel{subsec:mdp}{{3.3}{31}{Markov Decision Processes (MDP)}{subsection.3.3}{}}
\citation{Sutton-introRL}
\newlabel{eq:1}{{3.1}{32}{Markov Decision Processes (MDP)}{equation.3.1}{}}
\newlabel{eq:2}{{3.2}{33}{Markov Decision Processes (MDP)}{equation.3.2}{}}
\newlabel{eq:3}{{3.3}{33}{Markov Decision Processes (MDP)}{equation.3.3}{}}
\newlabel{eq:4}{{3.4}{33}{Markov Decision Processes (MDP)}{equation.3.4}{}}
\newlabel{eq:5}{{3.5}{33}{Markov Decision Processes (MDP)}{equation.3.5}{}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\newlabel{eq:6}{{3.6}{34}{Markov Decision Processes (MDP)}{equation.3.6}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.3.1}Optimality}{34}{subsubsection.3.3.1}}
\newlabel{optimality}{{3.3.1}{34}{Optimality}{subsubsection.3.3.1}{}}
\newlabel{eq:7}{{3.8}{34}{Optimality}{equation.3.8}{}}
\newlabel{eq:8}{{3.9}{34}{Optimality}{equation.3.9}{}}
\citation{Sutton-introRL}
\citation{Young99probabilisticmethods}
\citation{mdp-pieraccini}
\citation{mdp-bellmann}
\citation{Sutton-introRL}
\newlabel{eq:9}{{3.10}{35}{Optimality}{equation.3.10}{}}
\newlabel{eq:10}{{3.11}{35}{Optimality}{equation.3.11}{}}
\newlabel{eq:11}{{3.12}{35}{Optimality}{equation.3.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.4}Composing Dialog Management as an MDP}{36}{subsection.3.4}}
\newlabel{dialog-mdp}{{3.4}{36}{Composing Dialog Management as an MDP}{subsection.3.4}{}}
\citation{Larsson:2000:ISD:973935.973943}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces Dialog represented as a Markov Decision Process }}{37}{figure.3}}
\newlabel{chat-world3}{{3}{37}{Dialog represented as a Markov Decision Process}{figure.3}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Agent-Environment Interaction }}{39}{figure.4}}
\newlabel{chat-world}{{4}{39}{Agent-Environment Interaction}{figure.4}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Agent-Environment Interaction in the form of a chatbot application }}{40}{figure.5}}
\newlabel{chat-world2}{{5}{40}{Agent-Environment Interaction in the form of a chatbot application}{figure.5}{}}
\citation{rl_overview}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.5}Dialog Policy Optimization}{41}{subsection.3.5}}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Dialog Policy Optimization Methods }}{41}{figure.6}}
\newlabel{mdp-methods}{{6}{41}{Dialog Policy Optimization Methods}{figure.6}{}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.1}Value Iterative Methods}{42}{subsubsection.3.5.1}}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\newlabel{eq:12}{{3.13}{43}{Value Iterative Methods}{equation.3.13}{}}
\newlabel{eq:13}{{3.14}{43}{Value Iterative Methods}{equation.3.14}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.1}Dynamic Programming}{43}{paragraph.3.5.1.1}}
\newlabel{dp}{{3.5.1.1}{43}{Dynamic Programming}{paragraph.3.5.1.1}{}}
\newlabel{eq:dp-update}{{3.15}{43}{Dynamic Programming}{equation.3.15}{}}
\citation{sutton1988TFDearning}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.2}Monte Carlo Learning }{44}{paragraph.3.5.1.2}}
\newlabel{mc-learning}{{3.5.1.2}{44}{Monte Carlo Learning}{paragraph.3.5.1.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.3}Temporal Difference(TD) Learning }{44}{paragraph.3.5.1.3}}
\citation{sutton1988TFDearning}
\newlabel{td-learning}{{3.5.1.3}{45}{Temporal Difference(TD) Learning}{paragraph.3.5.1.3}{}}
\newlabel{eq:td-error}{{3.16}{45}{Temporal Difference(TD) Learning}{equation.3.16}{}}
\newlabel{eq:td-update}{{3.17}{45}{Temporal Difference(TD) Learning}{equation.3.17}{}}
\citation{watkins1989Qlearning}
\newlabel{eq:sarsa-update}{{3.18}{46}{Temporal Difference(TD) Learning}{equation.3.18}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {1}{\ignorespaces SARSA}}{46}{algocf.1}}
\newlabel{alg:sarsa}{{1}{46}{Temporal Difference(TD) Learning}{algocf.1}{}}
\newlabel{eq:q-update}{{3.19}{47}{Temporal Difference(TD) Learning}{equation.3.19}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {2}{\ignorespaces Q-Learning}}{47}{algocf.2}}
\newlabel{alg:q-learning}{{2}{47}{Temporal Difference(TD) Learning}{algocf.2}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.4}Sample Efficiency}{47}{paragraph.3.5.1.4}}
\citation{adam2012experience}
\citation{verleysen2005curse}
\citation{hornik1989multilayer}
\@writefile{toc}{\contentsline {paragraph}{\numberline {3.5.1.5}Function Approximation}{48}{paragraph.3.5.1.5}}
\newlabel{fn_aprrox}{{3.5.1.5}{48}{Function Approximation}{paragraph.3.5.1.5}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.2}Policy Iterative Methods}{49}{subsubsection.3.5.2}}
\newlabel{policy_methods}{{3.5.2}{49}{Policy Iterative Methods}{subsubsection.3.5.2}{}}
\citation{Sutton-introRL}
\newlabel{eq:17}{{3.25}{50}{Policy Iterative Methods}{equation.3.25}{}}
\newlabel{eq:obj_value}{{3.28}{51}{Policy Iterative Methods}{equation.3.28}{}}
\citation{Sutton-introRL}
\citation{Sutton_pg}
\citation{Sutton-introRL}
\citation{Sutton_pg}
\newlabel{eq:vpg_update}{{3.30}{52}{Policy Iterative Methods}{equation.3.30}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.5.3}Actor-Critic Methods}{52}{subsubsection.3.5.3}}
\newlabel{section:ac-methods}{{3.5.3}{52}{Actor-Critic Methods}{subsubsection.3.5.3}{}}
\newlabel{eq:pg-theorem}{{3.31}{52}{Actor-Critic Methods}{equation.3.31}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Actor-Critic Environment Interaction }}{53}{figure.7}}
\newlabel{a-c}{{7}{53}{Actor-Critic Environment Interaction}{figure.7}{}}
\newlabel{eq:ac-conv}{{3.32}{53}{Actor-Critic Methods}{equation.3.32}{}}
\citation{peters2005natural}
\citation{Sutton_pg}
\citation{peters2005natural}
\citation{Sutton_pg}
\citation{bordes2016learning}
\citation{liu2016not}
\newlabel{eq:pg-compatible}{{3.33}{54}{Actor-Critic Methods}{equation.3.33}{}}
\newlabel{eq:ac-error}{{3.34}{54}{Actor-Critic Methods}{equation.3.34}{}}
\newlabel{eq:pg-f}{{3.35}{54}{Actor-Critic Methods}{equation.3.35}{}}
\citation{Williams:2007:POM:1221595.1221967}
\citation{DBLP:journals/corr/abs-1711-01731}
\citation{lemon2006evaluating}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.6}Evaluation and Reward Estimation}{55}{subsection.3.6}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.1}Heuristic Rewards}{55}{subsubsection.3.6.1}}
\citation{walker1997paradise}
\citation{larsen2003issues}
\citation{mataric1994reward}
\citation{ng1999policy}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.2}The Paradise Framework}{56}{subsubsection.3.6.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.6.3}Reward Shaping}{56}{subsubsection.3.6.3}}
\newlabel{eg:reward-shaping-condition}{{3.38}{57}{Reward Shaping}{equation.3.38}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {3.7}Auxiliary RL terminology}{57}{subsection.3.7}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.1}Model-based and Model-free}{58}{subsubsection.3.7.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.2}Episodic and Continuous Tasks}{58}{subsubsection.3.7.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.3}On-line and Off-line}{59}{subsubsection.3.7.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.4}On Policy and Off Policy}{59}{subsubsection.3.7.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {3.7.5}Exploration and Exploitation}{59}{subsubsection.3.7.5}}
\citation{Goodfellow-et-al-2016}
\@writefile{toc}{\contentsline {section}{\numberline {4}Deep Learning}{61}{section.4}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.1}Overview}{61}{subsection.4.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.2}Deep Feedforward Networks}{61}{subsection.4.2}}
\citation{LeCun:1998:CNI:303568.303704}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Fully Connected Neural Network }}{63}{figure.8}}
\newlabel{nn-fully-connected}{{8}{63}{Fully Connected Neural Network}{figure.8}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.3}Loss Functions}{63}{subsection.4.3}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.1}Maximum Likelihood Estimation}{64}{subsubsection.4.3.1}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.3.2}Approximating Conditional Distributions with Maximum Likelihood}{65}{subsubsection.4.3.2}}
\newlabel{eq:mse_loss}{{4.7}{65}{Approximating Conditional Distributions with Maximum Likelihood}{equation.4.7}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.4}Output Units}{66}{subsection.4.4}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.1}Linear Units}{66}{subsubsection.4.4.1}}
\newlabel{linear_unit}{{4.4.1}{66}{Linear Units}{subsubsection.4.4.1}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.2}Sigmoid Units}{66}{subsubsection.4.4.2}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.4.3}Softmax Units}{67}{subsubsection.4.4.3}}
\newlabel{softmax}{{4.4.3}{67}{Softmax Units}{subsubsection.4.4.3}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.5}Hidden Units}{68}{subsection.4.5}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.1}Rectified Linear Units(ReLU)}{68}{subsubsection.4.5.1}}
\citation{jarrett2009best}
\citation{maas2013rectifier}
\citation{he2015delving}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Rectified Linear Unit }}{69}{figure.9}}
\newlabel{relu}{{9}{69}{Rectified Linear Unit}{figure.9}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.5.2}The Hyperbolic Tangent and Logistic Sigmoid}{70}{subsubsection.4.5.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Logistic Sigmoid Unit }}{71}{figure.10}}
\newlabel{sigmoid}{{10}{71}{Logistic Sigmoid Unit}{figure.10}{}}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Hyperbolic Tangent Unit }}{72}{figure.11}}
\newlabel{tanh}{{11}{72}{Hyperbolic Tangent Unit}{figure.11}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.6}Architecture}{72}{subsection.4.6}}
\citation{Goodfellow-et-al-2016}
\citation{cauchy1847methode}
\citation{Goodfellow-et-al-2016}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces General Architecture of a Neural Network }}{73}{figure.12}}
\newlabel{nn_arch}{{12}{73}{General Architecture of a Neural Network}{figure.12}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {4.7}Gradient Based Learning}{73}{subsection.4.7}}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces The Process of Gradient Descent\cite  {Goodfellow-et-al-2016} }}{74}{figure.13}}
\newlabel{grad_descent}{{13}{74}{The Process of Gradient Descent\cite {Goodfellow-et-al-2016}}{figure.13}{}}
\citation{rumelhart1986learning}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.1}Back-Propagation}{75}{subsubsection.4.7.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Back Propagating Errors Through a Neural Network }}{75}{figure.14}}
\newlabel{back_prop}{{14}{75}{Back Propagating Errors Through a Neural Network}{figure.14}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {3}{\ignorespaces Forward Propagation through a deep neural network and the loss computation}}{76}{algocf.3}}
\newlabel{alg:forward-prop}{{3}{76}{Back-Propagation}{algocf.3}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {4}{\ignorespaces Back Propagation}}{77}{algocf.4}}
\newlabel{alg:back-prop}{{4}{77}{Back-Propagation}{algocf.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {4.7.2}Stochastic Gradient Descent(SGD)}{77}{subsubsection.4.7.2}}
\newlabel{sgd}{{4.7.2}{77}{Stochastic Gradient Descent(SGD)}{subsubsection.4.7.2}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {5}{\ignorespaces Stochastic Gradient Descent Algorithm}}{78}{algocf.5}}
\newlabel{alg:sgd}{{5}{78}{Stochastic Gradient Descent(SGD)}{algocf.5}{}}
\citation{Williams92REINFORCE}
\@writefile{toc}{\contentsline {section}{\numberline {5}Neural Dialog Management}{79}{section.5}}
\newlabel{dm-with-drl}{{5}{79}{Neural Dialog Management}{section.5}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.1}Overview}{79}{subsection.5.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.2}REINFORCE}{79}{subsection.5.2}}
\newlabel{eq:pg-expectation}{{5.1}{80}{REINFORCE}{equation.5.1}{}}
\newlabel{eq:reinforce-update}{{5.4}{80}{REINFORCE}{equation.5.4}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.1}REINFORCE Algorithm}{81}{subsubsection.5.2.1}}
\newlabel{reinforce}{{5.2.1}{81}{REINFORCE Algorithm}{subsubsection.5.2.1}{}}
\@writefile{loa}{\contentsline {algocf}{\numberline {6}{\ignorespaces REINFORCE}}{81}{algocf.6}}
\newlabel{alg:reinforce}{{6}{81}{REINFORCE Algorithm}{algocf.6}{}}
\citation{kingma2014adam}
\citation{Sutton_pg}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.2.2}Policy Network}{82}{subsubsection.5.2.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Policy Neural Network }}{83}{figure.15}}
\newlabel{nn-policy}{{15}{83}{Policy Neural Network}{figure.15}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {5.3}Advantage Actor Critic}{83}{subsection.5.3}}
\newlabel{a2c-section}{{5.3}{83}{Advantage Actor Critic}{subsection.5.3}{}}
\citation{Sutton_pg}
\citation{Sutton-introRL}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.1}Advantage Function}{84}{subsubsection.5.3.1}}
\newlabel{eq:baseline}{{5.5}{84}{Advantage Function}{equation.5.5}{}}
\newlabel{eq:adv}{{5.6}{85}{Advantage Function}{equation.5.6}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {16}{\ignorespaces Actor-Critic Environment Interaction }}{85}{figure.16}}
\newlabel{a2c}{{16}{85}{Actor-Critic Environment Interaction}{figure.16}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.2}A2C Algorithm}{85}{subsubsection.5.3.2}}
\citation{Williams92REINFORCE}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.3}Actor Network}{86}{subsubsection.5.3.3}}
\@writefile{loa}{\contentsline {algocf}{\numberline {7}{\ignorespaces Advantage Actor Critic Algorithm}}{87}{algocf.7}}
\newlabel{alg:a2c}{{7}{87}{A2C Algorithm}{algocf.7}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {17}{\ignorespaces Actor Network }}{88}{figure.17}}
\newlabel{nn-actor}{{17}{88}{Actor Network}{figure.17}{}}
\citation{kingma2014adam}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {5.3.4}Critic Network}{89}{subsubsection.5.3.4}}
\@writefile{lof}{\contentsline {figure}{\numberline {18}{\ignorespaces Critic Network }}{89}{figure.18}}
\newlabel{nn-critic}{{18}{89}{Critic Network}{figure.18}{}}
\citation{python}
\citation{tensorflow}
\citation{keras}
\@writefile{toc}{\contentsline {section}{\numberline {6}Experiments and Results}{91}{section.6}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.1}Overview}{91}{subsection.6.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.2}Learning Simple Dialog Strategies}{91}{subsection.6.2}}
\citation{Singh_mdp}
\citation{walker2000evaluation}
\citation{roy2000spoken}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.1}Experimental Setup}{92}{subsubsection.6.2.1}}
\newlabel{expt-setup}{{6.2.1}{92}{Experimental Setup}{subsubsection.6.2.1}{}}
\newlabel{eq:trans-prob1}{{6.1}{92}{Experimental Setup}{equation.6.1}{}}
\citation{Larsson:2000:ISD:973935.973943}
\newlabel{eq:trans-prob2}{{6.2}{93}{Experimental Setup}{equation.6.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {19}{\ignorespaces State Transition Model }}{94}{figure.19}}
\newlabel{state-trans}{{19}{94}{State Transition Model}{figure.19}{}}
\newlabel{eq:trans-prob3}{{6.5}{94}{Experimental Setup}{equation.6.5}{}}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces User Simulation Model}}{95}{table.1}}
\newlabel{table:user-sim}{{1}{95}{User Simulation Model}{table.1}{}}
\citation{Sutton-introRL}
\newlabel{reward_func}{{6.6}{97}{Experimental Setup}{equation.6.6}{}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces System Actions}}{97}{table.2}}
\newlabel{table:actions}{{2}{97}{System Actions}{table.2}{}}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.2}Learning with A2C}{98}{subsubsection.6.2.2}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.1}Results}{98}{paragraph.6.2.2.1}}
\@writefile{lof}{\contentsline {figure}{\numberline {20}{\ignorespaces A2C Learning Curve }}{100}{figure.20}}
\newlabel{a2c-plot}{{20}{100}{A2C Learning Curve}{figure.20}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.2}Effect of the Discount Factor}{101}{paragraph.6.2.2.2}}
\newlabel{a2c_df_effect}{{6.2.2.2}{101}{Effect of the Discount Factor}{paragraph.6.2.2.2}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {21}{\ignorespaces Effect of the Discount Factor on A2C Learning }}{102}{figure.21}}
\newlabel{a2c_dis_fact}{{21}{102}{Effect of the Discount Factor on A2C Learning}{figure.21}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.2.3}Effect of Reward Magnitude}{103}{paragraph.6.2.2.3}}
\@writefile{lof}{\contentsline {figure}{\numberline {22}{\ignorespaces Effect of the Absolute Reward Magnitude on A2C Learning }}{104}{figure.22}}
\newlabel{a2c_reward_mag}{{22}{104}{Effect of the Absolute Reward Magnitude on A2C Learning}{figure.22}{}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {subsubsection}{\numberline {6.2.3}Learning with REINFORCE}{105}{subsubsection.6.2.3}}
\newlabel{reward_func_10}{{6.7}{105}{Learning with REINFORCE}{equation.6.7}{}}
\@writefile{toc}{\contentsline {paragraph}{\numberline {6.2.3.1}Results}{105}{paragraph.6.2.3.1}}
\newlabel{reinf_pre_results}{{6.2.3.1}{105}{Results}{paragraph.6.2.3.1}{}}
\@writefile{lof}{\contentsline {figure}{\numberline {23}{\ignorespaces REINFORCE Learning Curve }}{107}{figure.23}}
\newlabel{reinforce-plot}{{23}{107}{REINFORCE Learning Curve}{figure.23}{}}
\@writefile{toc}{\contentsline {subsection}{\numberline {6.3}Summary}{109}{subsection.6.3}}
\citation{Sutton-introRL}
\@writefile{toc}{\contentsline {section}{\numberline {7}Conclusions}{110}{section.7}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.1}Conclusion}{110}{subsection.7.1}}
\@writefile{toc}{\contentsline {subsection}{\numberline {7.2}Future Work}{110}{subsection.7.2}}
\bibstyle{apa}
\bibdata{references}
\bibcite{macwhinne_lang_evol}{{1}{}{{}}{{}}}
\bibcite{turing_mind}{{2}{}{{}}{{}}}
\bibcite{kurzweil_sing}{{3}{}{{}}{{}}}
\bibcite{Weizenbaum:1966:ECP:365153.365168}{{4}{}{{}}{{}}}
\bibcite{ncf2017}{{5}{}{{}}{{}}}
\bibcite{frey2017future}{{6}{}{{}}{{}}}
\bibcite{Tao_of_CHI}{{7}{}{{}}{{}}}
\bibcite{zue_jupiter}{{8}{}{{}}{{}}}
\bibcite{Larsson:2000:ISD:973935.973943}{{9}{}{{}}{{}}}
\bibcite{mdp-bellmann}{{10}{}{{}}{{}}}
\@writefile{toc}{\contentsline {section}{\numberline {8}References}{112}{section.8}}
\bibcite{mdp-pieraccini}{{11}{}{{}}{{}}}
\bibcite{Young99probabilisticmethods}{{12}{}{{}}{{}}}
\bibcite{Singh_mdp}{{13}{}{{}}{{}}}
\bibcite{Pietquin_mdp}{{14}{}{{}}{{}}}
\bibcite{Dhingra2016EndtoEndRL}{{15}{}{{}}{{}}}
\bibcite{Cuayhuitl2016SimpleDSAS}{{16}{}{{}}{{}}}
\bibcite{Li17e2eDS}{{17}{}{{}}{{}}}
\bibcite{HakkaniTr2016NLU}{{18}{}{{}}{{}}}
\bibcite{Wen_NLG}{{19}{}{{}}{{}}}
\bibcite{hochreiter1997long}{{20}{}{{}}{{}}}
\bibcite{Schatzmann_agenda_sim}{{21}{}{{}}{{}}}
\bibcite{Li_user_sim}{{22}{}{{}}{{}}}
\bibcite{Mnih_DQN}{{23}{}{{}}{{}}}
\bibcite{tensorflow}{{24}{}{{}}{{}}}
\bibcite{Sutskever_seq_2seq}{{25}{}{{}}{{}}}
\bibcite{karpathy_rnn}{{26}{}{{}}{{}}}
\bibcite{hochreiter1998vanishing}{{27}{}{{}}{{}}}
\bibcite{Sukhbaatar_end2end_mem_net}{{28}{}{{}}{{}}}
\bibcite{babl}{{29}{}{{}}{{}}}
\bibcite{bordes_weston_e2e}{{30}{}{{}}{{}}}
\bibcite{Su_continous_dm}{{31}{}{{}}{{}}}
\bibcite{Schulman_trpo}{{32}{}{{}}{{}}}
\bibcite{Sutton_pg}{{33}{}{{}}{{}}}
\bibcite{Lin1992}{{34}{}{{}}{{}}}
\bibcite{Williams_HCN_e2e}{{35}{}{{}}{{}}}
\bibcite{ds_survey}{{36}{}{{}}{{}}}
\bibcite{Pieraccini2006WhereDW}{{37}{}{{}}{{}}}
\bibcite{ml_dst_review}{{38}{}{{}}{{}}}
\bibcite{Sutton-introRL}{{39}{}{{}}{{}}}
\bibcite{Young_dst_dbn}{{40}{}{{}}{{}}}
\bibcite{roy2000spoken}{{41}{}{{}}{{}}}
\bibcite{Henderson:2008:MMP:1557690.1557710}{{42}{}{{}}{{}}}
\bibcite{Young:2010:HIS:1621140.1621240}{{43}{}{{}}{{}}}
\bibcite{generative_dst_limitation}{{44}{}{{}}{{}}}
\bibcite{Lee2013StructuredDM}{{45}{}{{}}{{}}}
\bibcite{Henderson2014WordBasedDS}{{46}{}{{}}{{}}}
\bibcite{Henderson_dst_2014}{{47}{}{{}}{{}}}
\bibcite{DBLP:journals/corr/MrksicSWTY16}{{48}{}{{}}{{}}}
\bibcite{DBLP:journals/corr/abs-1711-01731}{{49}{}{{}}{{}}}
\bibcite{henderson_interdomain}{{50}{}{{}}{{}}}
\bibcite{lopez-cozar-simulation}{{51}{}{{}}{{}}}
\bibcite{Schatzmann_stat_user_sim}{{52}{}{{}}{{}}}
\bibcite{Chung_user_sim}{{53}{}{{}}{{}}}
\bibcite{Lopez-Cozar_user-sim}{{54}{}{{}}{{}}}
\bibcite{Cuayhuitl2006LearningMD}{{55}{}{{}}{{}}}
\bibcite{levin_mdp}{{56}{}{{}}{{}}}
\bibcite{4430164}{{57}{}{{}}{{}}}
\bibcite{Georgila2006UserSF}{{58}{}{{}}{{}}}
\bibcite{Cuayhuitl2005HumancomputerDS}{{59}{}{{}}{{}}}
\bibcite{Scheffler_sim}{{60}{}{{}}{{}}}
\bibcite{Schatzmann2007StatisticalUS}{{61}{}{{}}{{}}}
\bibcite{georgila1998integrated}{{62}{}{{}}{{}}}
\bibcite{chai2001natural}{{63}{}{{}}{{}}}
\bibcite{su2013dialoguegame}{{64}{}{{}}{{}}}
\bibcite{ELVIS}{{65}{}{{}}{{}}}
\bibcite{Shriver_unified}{{66}{}{{}}{{}}}
\bibcite{TRAIN}{{67}{}{{}}{{}}}
\bibcite{ferguson1998trips}{{68}{}{{}}{{}}}
\bibcite{Levin97astochastic}{{69}{}{{}}{{}}}
\bibcite{rl_overview}{{70}{}{{}}{{}}}
\bibcite{sutton1988TFDearning}{{71}{}{{}}{{}}}
\bibcite{watkins1989Qlearning}{{72}{}{{}}{{}}}
\bibcite{adam2012experience}{{73}{}{{}}{{}}}
\bibcite{verleysen2005curse}{{74}{}{{}}{{}}}
\bibcite{hornik1989multilayer}{{75}{}{{}}{{}}}
\bibcite{peters2005natural}{{76}{}{{}}{{}}}
\bibcite{bordes2016learning}{{77}{}{{}}{{}}}
\bibcite{liu2016not}{{78}{}{{}}{{}}}
\bibcite{Williams:2007:POM:1221595.1221967}{{79}{}{{}}{{}}}
\bibcite{lemon2006evaluating}{{80}{}{{}}{{}}}
\bibcite{walker1997paradise}{{81}{}{{}}{{}}}
\bibcite{larsen2003issues}{{82}{}{{}}{{}}}
\bibcite{mataric1994reward}{{83}{}{{}}{{}}}
\bibcite{ng1999policy}{{84}{}{{}}{{}}}
\bibcite{Goodfellow-et-al-2016}{{85}{}{{}}{{}}}
\bibcite{LeCun:1998:CNI:303568.303704}{{86}{}{{}}{{}}}
\bibcite{jarrett2009best}{{87}{}{{}}{{}}}
\bibcite{maas2013rectifier}{{88}{}{{}}{{}}}
\bibcite{he2015delving}{{89}{}{{}}{{}}}
\bibcite{cauchy1847methode}{{90}{}{{}}{{}}}
\bibcite{rumelhart1986learning}{{91}{}{{}}{{}}}
\bibcite{Williams92REINFORCE}{{92}{}{{}}{{}}}
\bibcite{kingma2014adam}{{93}{}{{}}{{}}}
\bibcite{python}{{94}{}{{}}{{}}}
\bibcite{keras}{{95}{}{{}}{{}}}
\bibcite{walker2000evaluation}{{96}{}{{}}{{}}}
\providecommand\NAT@force@numbers{}\NAT@force@numbers
